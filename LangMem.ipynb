{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMskphgEwVb2Rx0lDSdpPOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trashchenkov/LLM-First-Touch/blob/main/LangMem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain langchain-community langchain-gigachat langmem"
      ],
      "metadata": {
        "id": "CffYhhqa_Tc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface  langchain-groq"
      ],
      "metadata": {
        "id": "kaowHTZ3nUFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.base import _get_provider_list\n",
        "\n",
        "# Вывод списка доступных провайдеров\n",
        "print(_get_provider_list())\n"
      ],
      "metadata": {
        "id": "dxX-5xLnh_qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_gigachat.chat_models import GigaChat\n",
        "from langgraph.func import entrypoint\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langmem import create_memory_store_manager\n",
        "from langchain.embeddings import init_embeddings\n",
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "gc_key = userdata.get('GIGA')\n",
        "groq_key = userdata.get('GROQ')\n",
        "\n",
        "store = InMemoryStore( #\n",
        "    index={\n",
        "        \"dims\": 1024,\n",
        "        \"embed\": \"huggingface:intfloat/multilingual-e5-large-instruct\",\n",
        "    }\n",
        ")\n",
        "llm = GigaChat(\n",
        "    credentials=gc_key, model='GigaChat-Max',\n",
        "    verify_ssl_certs=False,\n",
        "    scope=\"GIGACHAT_API_CORP\"\n",
        ")\n",
        "\n",
        "llama = ChatGroq(\n",
        "    model='llama-3.3-70b-versatile',\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "\n",
        "# Create memory manager Runnable to extract memories from conversations\n",
        "memory_manager = create_memory_store_manager(\n",
        "    llama,\n",
        "    # Store memories in the \"memories\" namespace (aka directory)\n",
        "    namespace=(\"memories\",),  #\n",
        ")\n",
        "\n",
        "@entrypoint(store=store)  # Create a LangGraph workflow\n",
        "async def chat(message: str):\n",
        "    response = llm.invoke(message)\n",
        "\n",
        "    # memory_manager extracts memories from conversation history\n",
        "    # We'll provide it in OpenAI's message format\n",
        "    to_process = {\"messages\": [{\"role\": \"user\", \"content\": message}] + [response]}\n",
        "    await memory_manager.ainvoke(to_process)  #\n",
        "    return response.content\n",
        "# Run conversation as normal\n",
        "response = await chat.ainvoke(\n",
        "    \"Я люблю кошек. Раньше у меня была кошка по кличке Шанти.\",\n",
        ")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "w1sceCrOnewm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(store.search((\"memories\",)))"
      ],
      "metadata": {
        "id": "ACZ_4lc2rb0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mem in store.search((\"memories\",)):\n",
        "    print(mem)"
      ],
      "metadata": {
        "id": "0AfbPRcfyMzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lpa7x9gEb-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}